{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nivea5678/Yeti-Analytics/blob/main/Optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WszdPlRywVhC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import opinion_lexicon\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "U3ctoF5twYs-",
        "outputId": "65d4815c-d551-4044-a303-3c25dfdf99bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dfe23c86-fd65-4deb-91f3-c1efe2941edf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dfe23c86-fd65-4deb-91f3-c1efe2941edf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Yeti Analytics.xlsx to Yeti Analytics.xlsx\n"
          ]
        }
      ],
      "source": [
        "# loading the data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lM6_kw31worb",
        "outputId": "84ea32c8-4bb1-4619-a7b5-88f4f71d021e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a2983e82-8562-40f5-9f91-492bb2ad9e31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nice hotel expensive parking got good deal sta...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok nothing special charge diamond member hilto...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great stay great stay, went seahawk game aweso...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20486</th>\n",
              "      <td>best kept secret 3rd time staying charm, not 5...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20487</th>\n",
              "      <td>great location price view hotel great quick pl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20488</th>\n",
              "      <td>ok just looks nice modern outside, desk staff ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20489</th>\n",
              "      <td>hotel theft ruined vacation hotel opened sept ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20490</th>\n",
              "      <td>people talking, ca n't believe excellent ratin...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20491 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2983e82-8562-40f5-9f91-492bb2ad9e31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-7ece68aa-fd29-4110-8410-3d9b375910f3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ece68aa-fd29-4110-8410-3d9b375910f3')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-7ece68aa-fd29-4110-8410-3d9b375910f3 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2983e82-8562-40f5-9f91-492bb2ad9e31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2983e82-8562-40f5-9f91-492bb2ad9e31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  Review  Rating\n",
              "0      nice hotel expensive parking got good deal sta...       4\n",
              "1      ok nothing special charge diamond member hilto...       2\n",
              "2      nice rooms not 4* experience hotel monaco seat...       3\n",
              "3      unique, great stay, wonderful time hotel monac...       5\n",
              "4      great stay great stay, went seahawk game aweso...       5\n",
              "...                                                  ...     ...\n",
              "20486  best kept secret 3rd time staying charm, not 5...       5\n",
              "20487  great location price view hotel great quick pl...       4\n",
              "20488  ok just looks nice modern outside, desk staff ...       2\n",
              "20489  hotel theft ruined vacation hotel opened sept ...       1\n",
              "20490  people talking, ca n't believe excellent ratin...       2\n",
              "\n",
              "[20491 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Load the dataset into dataframe\n",
        "df = pd.read_excel('Yeti Analytics.xlsx')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miIburRvws2Z",
        "outputId": "decf5aa9-a237-4864-9c17-64823546a0a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtzt58hTxOYb"
      },
      "outputs": [],
      "source": [
        "# Preprocessing the text\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['Review'] = df['Review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA5s6EfOxaXN",
        "outputId": "1c3c90f1-a680-4fe3-e5a7-fa303f78a563"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1U8cirQxtNT",
        "outputId": "40d2a4b0-d5f0-4641-b255-b1f7ebdc3e97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatization and stopword removal\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['Cleaned_Review'] = df['Review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0StJIfl_xy2W",
        "outputId": "dcecbae5-9fb7-4bb4-fad6-54b8af4002a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-08-04 20:21:26--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-08-04 20:21:26--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-08-04 20:21:26--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/content/gdrive/My Drive/glove_data/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 38s  \n",
            "\n",
            "2023-08-04 20:24:05 (5.19 MB/s) - ‘/content/gdrive/My Drive/glove_data/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/gdrive/My Drive/glove_data/glove.6B.zip\n",
            "  inflating: /content/gdrive/My Drive/glove_data/glove.6B.50d.txt  \n",
            "  inflating: /content/gdrive/My Drive/glove_data/glove.6B.100d.txt  \n",
            "  inflating: /content/gdrive/My Drive/glove_data/glove.6B.200d.txt  \n",
            "  inflating: /content/gdrive/My Drive/glove_data/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "!wget -P \"/content/gdrive/My Drive/glove_data\" \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "!unzip \"/content/gdrive/My Drive/glove_data/glove.6B.zip\" -d \"/content/gdrive/My Drive/glove_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LnrV76Ax5r6",
        "outputId": "41055568-3049-46b0-facb-8e8eb3bb9af0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "193/193 [==============================] - 83s 365ms/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 8.8094e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "193/193 [==============================] - 85s 440ms/step - loss: 2.7561e-04 - accuracy: 1.0000 - val_loss: 1.2260e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "193/193 [==============================] - 83s 433ms/step - loss: 1.2262e-04 - accuracy: 1.0000 - val_loss: 3.1944e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "193/193 [==============================] - 83s 429ms/step - loss: 7.6581e-05 - accuracy: 1.0000 - val_loss: 1.2980e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "193/193 [==============================] - 84s 437ms/step - loss: 6.4800e-05 - accuracy: 1.0000 - val_loss: 5.2615e-08 - val_accuracy: 1.0000\n",
            "449/449 [==============================] - 29s 64ms/step - loss: 5.2615e-08 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Convert all non-positive ratings to negative\n",
        "df['Rating'] = df['Rating'].apply(lambda x: 'positive' if x == 'positive' else 'negative')\n",
        "\n",
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Review'], df['Rating'], test_size=0.7, random_state=42)\n",
        "\n",
        "# Tokenization and Padding\n",
        "max_sequence_length = 100\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Mapping class labels to binary values\n",
        "y_train_binary = (y_train == 'positive').astype(int)\n",
        "y_test_binary = (y_test == 'positive').astype(int)\n",
        "\n",
        "# Mapping class labels to start from 0\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding the labels\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train_encoded.reshape(-1, 1))\n",
        "y_test_onehot = onehot_encoder.transform(y_test_encoded.reshape(-1, 1))\n",
        "\n",
        "# Modify the vocab_size if needed\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for the unknown word token\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_index = {}\n",
        "with open(\"/content/gdrive/My Drive/glove_data/glove.6B.100d.txt\", encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Update the model with pre-trained embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification with sigmoid activation\n",
        "\n",
        "# Rest of the code remains unchanged\n",
        "\n",
        "# ... (continue with the rest of the code)\n",
        "# Compiling and train the model with custom learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Experiment with different learning rates\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.fit(X_train_padded, y_train_binary, validation_data=(X_test_padded, y_test_binary), epochs=5, batch_size=32)\n",
        "\n",
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_binary)\n",
        "print('Accuracy: %.2f%%' % (accuracy * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ej5m66I21d",
        "outputId": "4d3dff84-0128-4390-b354-d8a97ce6de1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "513/513 [==============================] - 144s 264ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 1.2873e-08 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "513/513 [==============================] - 131s 255ms/step - loss: 2.0758e-04 - accuracy: 1.0000 - val_loss: 1.7374e-10 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "513/513 [==============================] - 129s 252ms/step - loss: 7.0688e-05 - accuracy: 1.0000 - val_loss: 1.3167e-11 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "513/513 [==============================] - 127s 247ms/step - loss: 8.7841e-05 - accuracy: 1.0000 - val_loss: 1.1566e-12 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "513/513 [==============================] - 128s 249ms/step - loss: 3.7454e-05 - accuracy: 1.0000 - val_loss: 1.7073e-13 - val_accuracy: 1.0000\n",
            "129/129 [==============================] - 9s 69ms/step - loss: 1.7073e-13 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# ... (previous code up to line 36)\n",
        "\n",
        "# Convert all non-positive ratings to negative\n",
        "df['Rating'] = df['Rating'].apply(lambda x: 'positive' if x == 'positive' else 'negative')\n",
        "\n",
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Review'], df['Rating'], test_size=0.2, random_state=42)  # Change test_size to 0.2\n",
        "\n",
        "# Tokenization and Padding\n",
        "max_sequence_length = 100\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Mapping class labels to binary values\n",
        "y_train_binary = (y_train == 'positive').astype(int)\n",
        "y_test_binary = (y_test == 'positive').astype(int)\n",
        "\n",
        "# Modify the vocab_size if needed\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for the unknown word token\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_index = {}\n",
        "with open(\"/content/gdrive/My Drive/glove_data/glove.6B.100d.txt\", encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Update the model with pre-trained embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))  # Add dropout after LSTM\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.5))  # Add dropout after LSTM\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Add dropout after dense layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification with sigmoid activation\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_padded, y_train_binary, validation_data=(X_test_padded, y_test_binary), epochs=5, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_binary)\n",
        "print('Accuracy: %.2f%%' % (accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IkTKe6OIEVs",
        "outputId": "c841fc25-b1e1-4a02-a73e-f97f29bd06a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "257/257 [==============================] - 84s 250ms/step - loss: 0.0601 - accuracy: 0.9942 - val_loss: 9.7421e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "257/257 [==============================] - 58s 224ms/step - loss: 0.0229 - accuracy: 0.9996 - val_loss: 2.8528e-08 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "257/257 [==============================] - 60s 232ms/step - loss: 0.0195 - accuracy: 0.9998 - val_loss: 3.0764e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "257/257 [==============================] - 57s 220ms/step - loss: 0.0179 - accuracy: 0.9999 - val_loss: 6.2612e-10 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "257/257 [==============================] - 55s 213ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.6013e-10 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "257/257 [==============================] - 57s 222ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 5.4202e-11 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "257/257 [==============================] - 55s 216ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.0998e-11 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "257/257 [==============================] - 54s 209ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 9.7180e-12 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "257/257 [==============================] - 57s 220ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 5.1997e-12 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "257/257 [==============================] - 55s 214ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.5296e-12 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "257/257 [==============================] - 58s 224ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4054e-12 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "257/257 [==============================] - 57s 222ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 8.1668e-13 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "257/257 [==============================] - 56s 218ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.7976e-13 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "257/257 [==============================] - 53s 208ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.9640e-13 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "257/257 [==============================] - 57s 224ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7571e-13 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "257/257 [==============================] - 55s 216ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1278e-13 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "257/257 [==============================] - 57s 222ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 6.9771e-14 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "257/257 [==============================] - 55s 214ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.9037e-14 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "257/257 [==============================] - 54s 212ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.3877e-14 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "257/257 [==============================] - 55s 216ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3162e-14 - val_accuracy: 1.0000\n",
            "129/129 [==============================] - 6s 47ms/step - loss: 2.3162e-14 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Update the model with pre-trained embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_padded, y_train_binary, validation_data=(X_test_padded, y_test_binary), epochs=10, batch_size=64, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_binary)\n",
        "print('Accuracy: %.2f%%' % (accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjSRPHLsQMCE",
        "outputId": "ebaba0c9-3bf8-452e-cc20-dcd9d023ea60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 48s 251ms/step - loss: 0.1843 - accuracy: 0.9744 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 28s 226ms/step - loss: 0.0506 - accuracy: 0.9966 - val_loss: 9.9218e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 27s 216ms/step - loss: 0.0445 - accuracy: 0.9985 - val_loss: 2.1084e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 26s 211ms/step - loss: 0.0422 - accuracy: 0.9994 - val_loss: 6.9187e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 26s 206ms/step - loss: 0.0415 - accuracy: 0.9996 - val_loss: 2.5205e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 25s 201ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.1162e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 27s 216ms/step - loss: 0.0362 - accuracy: 0.9999 - val_loss: 5.3773e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 26s 207ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 2.8621e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 26s 208ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.6790e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 25s 202ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 9.7924e-08 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 3s 47ms/step - loss: 9.7924e-08 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ... (previous code up to line 36)\n",
        "\n",
        "# Convert all non-positive ratings to negative\n",
        "df['Rating'] = df['Rating'].apply(lambda x: 'positive' if x == 'positive' else 'negative')\n",
        "\n",
        "# Using a smaller subset of the data\n",
        "subset_size = 10000  # Choose a smaller subset size\n",
        "df_subset = df.sample(n=subset_size, random_state=42)\n",
        "\n",
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_subset['Cleaned_Review'], df_subset['Rating'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization and Padding\n",
        "max_sequence_length = 100\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Mapping class labels to binary values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_binary = label_encoder.fit_transform(y_train)\n",
        "y_test_binary = label_encoder.transform(y_test)\n",
        "\n",
        "# Modify the vocab_size if needed\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for the unknown word token\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_index = {}\n",
        "with open(\"/content/gdrive/My Drive/glove_data/glove.6B.100d.txt\", encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Update the model with pre-trained embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_padded, y_train_binary, validation_data=(X_test_padded, y_test_binary), epochs=10, batch_size=64, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_binary)\n",
        "print('Accuracy: %.2f%%' % (accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLQjkOfBVmep",
        "outputId": "c1d7cc21-ad24-43f7-9c2d-9d601e11944f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "125/125 [==============================] - 69s 461ms/step - loss: 0.2747 - accuracy: 0.9494 - val_loss: 0.0859 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 54s 436ms/step - loss: 0.1549 - accuracy: 0.9910 - val_loss: 0.0518 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 58s 461ms/step - loss: 0.1248 - accuracy: 0.9995 - val_loss: 0.0357 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 54s 434ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 59s 471ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 54s 432ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 56s 450ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 54s 433ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 54s 431ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 58s 461ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 57s 453ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 58s 462ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 54s 434ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 55s 438ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 55s 438ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 57s 458ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 56s 452ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 55s 444ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 57s 453ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 56s 446ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 57s 453ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 56s 449ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 56s 448ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 56s 449ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 56s 448ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 57s 453ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 59s 469ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 57s 456ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 54s 436ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Update the model with pre-trained embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.2)))  # Apply recurrent dropout\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(16, recurrent_dropout=0.2)))  # Apply recurrent dropout\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='relu', kernel_regularizer='l2'))  # Apply L2 regularization\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid', kernel_regularizer='l2'))  # Apply L2 regularization\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping and Learning Rate Scheduler Callbacks\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, patience=2, verbose=1)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_padded, y_train_binary, validation_data=(X_test_padded, y_test_binary), epochs=30, batch_size=64, callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_binary)\n",
        "print('Accuracy: %.2f%%' % (accuracy * 100))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}